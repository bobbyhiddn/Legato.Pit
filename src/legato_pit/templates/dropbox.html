{% extends "base.html" %}

{% block title %}Motif - {{ app_name }}{% endblock %}

{% block head %}
<style>
/* Voice Recording Styles */
.record-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    padding: 2rem 1rem;
    gap: 1.5rem;
}

.record-btn {
    width: 120px;
    height: 120px;
    border-radius: 50%;
    border: 4px solid var(--border-color);
    background: var(--bg-tertiary);
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s ease;
    position: relative;
}

.record-btn:hover {
    border-color: var(--accent-red);
    background: rgba(248, 81, 73, 0.1);
}

.record-btn.recording {
    border-color: var(--accent-red);
    background: rgba(248, 81, 73, 0.15);
    animation: pulse-record 1.5s ease-in-out infinite;
}

.record-btn.recording:hover {
    background: rgba(248, 81, 73, 0.25);
}

.record-btn.paused {
    border-color: var(--accent-yellow);
    background: rgba(210, 153, 34, 0.15);
    animation: none;
}

.record-btn.paused:hover {
    background: rgba(210, 153, 34, 0.25);
}

@keyframes pulse-record {
    0%, 100% { box-shadow: 0 0 0 0 rgba(248, 81, 73, 0.4); }
    50% { box-shadow: 0 0 0 20px rgba(248, 81, 73, 0); }
}

.record-icon {
    width: 48px;
    height: 48px;
    border-radius: 50%;
    background: var(--accent-red);
    transition: all 0.2s ease;
}

.record-btn.recording .record-icon {
    width: 32px;
    height: 32px;
    border-radius: 6px;
}

.record-btn.paused .record-icon {
    width: 48px;
    height: 48px;
    border-radius: 50%;
    background: var(--accent-yellow);
}

.record-status {
    text-align: center;
}

.record-time {
    font-size: 2rem;
    font-weight: 600;
    font-family: 'SF Mono', 'Monaco', 'Consolas', monospace;
    color: var(--text-primary);
}

.record-hint {
    font-size: 0.875rem;
    color: var(--text-secondary);
    margin-top: 0.25rem;
}

.record-hint.recording {
    color: var(--accent-red);
}

.record-hint.paused {
    color: var(--accent-yellow);
}

/* Segment indicator */
.segment-indicator {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    font-size: 0.8rem;
    color: var(--text-secondary);
    margin-top: 0.25rem;
}

.segment-dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: var(--accent-green);
}

.segment-dot.pending {
    background: var(--accent-yellow);
}

.segment-count {
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
    padding: 0.125rem 0.5rem;
    background: var(--bg-tertiary);
    border-radius: 9999px;
    font-size: 0.75rem;
}

/* Audio Visualizer */
.audio-visualizer {
    width: 100%;
    max-width: 400px;
    height: 60px;
    background: var(--bg-tertiary);
    border-radius: 8px;
    overflow: hidden;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 3px;
    padding: 0 1rem;
}

.visualizer-bar {
    width: 4px;
    height: 100%;
    background: var(--accent-blue);
    border-radius: 2px;
    transition: height 0.05s ease;
}

.audio-visualizer.recording .visualizer-bar {
    background: var(--accent-red);
}

.audio-visualizer.paused .visualizer-bar {
    background: var(--accent-yellow);
}

/* Transcription Preview */
.transcription-preview {
    width: 100%;
    background: var(--bg-secondary);
    border: 1px solid var(--border-color);
    border-radius: 8px;
    padding: 1rem;
    display: none;
}

.transcription-preview.visible {
    display: block;
}

.transcription-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 0.75rem;
}

.transcription-label {
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.transcription-actions {
    display: flex;
    gap: 0.5rem;
}

.transcription-text {
    font-size: 0.95rem;
    line-height: 1.6;
    color: var(--text-primary);
    white-space: pre-wrap;
    word-break: break-word;
    max-height: 300px;
    overflow-y: auto;
}

.transcription-loading {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    color: var(--text-secondary);
}

.loading-spinner {
    width: 20px;
    height: 20px;
    border: 2px solid var(--border-color);
    border-top-color: var(--accent-blue);
    border-radius: 50%;
    animation: spin 0.8s linear infinite;
}

@keyframes spin {
    to { transform: rotate(360deg); }
}

/* Segment divider in transcript */
.segment-divider {
    display: block;
    margin: 0.75rem 0;
    padding: 0.25rem 0;
    border-top: 1px dashed var(--border-color);
    font-size: 0.7rem;
    color: var(--text-muted);
}

/* Recording Controls */
.recording-controls {
    display: flex;
    gap: 0.75rem;
    flex-wrap: wrap;
    justify-content: center;
}

.recording-controls .btn {
    min-width: 100px;
}

.btn-transcribe {
    position: relative;
}

.btn-transcribe .pending-badge {
    position: absolute;
    top: -6px;
    right: -6px;
    width: 18px;
    height: 18px;
    background: var(--accent-yellow);
    border-radius: 50%;
    font-size: 0.7rem;
    font-weight: 600;
    color: #000;
    display: flex;
    align-items: center;
    justify-content: center;
}

/* Voice unavailable state */
.voice-unavailable {
    text-align: center;
    padding: 2rem 1rem;
    color: var(--text-secondary);
}

.voice-unavailable .icon {
    font-size: 3rem;
    margin-bottom: 1rem;
    opacity: 0.5;
}

/* Tab disabled state */
.tab-btn.disabled {
    opacity: 0.5;
    cursor: not-allowed;
}
</style>
{% endblock %}

{% block content %}
<div class="dropbox">
    <header class="page-header">
        <h1>Motif</h1>
        <p class="subtitle">Drop an idea into the system</p>
    </header>

    <form action="{{ url_for('dropbox.upload') }}" method="POST" enctype="multipart/form-data" class="upload-form" id="uploadForm">
        <div class="form-section">
            <label class="form-label">Input Method</label>

            <div class="upload-tabs">
                <button type="button" class="tab-btn active" onclick="showTab('text')">Paste Text</button>
                <button type="button" class="tab-btn" onclick="showTab('file')">Upload File</button>
                <button type="button" class="tab-btn" id="voiceTabBtn" onclick="showTab('voice')">Record Voice</button>
            </div>

            <div id="tab-text" class="tab-content active">
                <textarea id="transcript" name="transcript"
                          class="form-textarea"
                          placeholder="Paste your motif here - a voice transcript, idea, thought, or any text to process..."
                          rows="10"></textarea>
                <span class="form-hint">Max 500KB</span>
            </div>

            <div id="tab-file" class="tab-content">
                <div class="file-upload-area" onclick="document.getElementById('file').click()">
                    <input type="file" id="file" name="file" accept=".txt,.md,.text" class="file-input">
                    <div class="file-upload-content">
                        <svg class="upload-icon" viewBox="0 0 24 24" width="48" height="48">
                            <path fill="currentColor" d="M9 16h6v-6h4l-7-7-7 7h4v6zm-4 2h14v2H5v-2z"/>
                        </svg>
                        <p class="upload-text">Tap to select file</p>
                        <p class="upload-hint">.txt or .md files only</p>
                    </div>
                </div>
                <div id="file-name" class="file-name-display"></div>
            </div>

            <div id="tab-voice" class="tab-content">
                <div id="voiceUnavailable" class="voice-unavailable" style="display: none;">
                    <div class="icon">ðŸŽ¤</div>
                    <p>Voice recording requires microphone access and a modern browser.</p>
                    <p class="form-hint">Make sure to allow microphone permissions when prompted.</p>
                </div>

                <div id="voiceRecorder" class="record-container">
                    <div class="audio-visualizer" id="audioVisualizer">
                        <!-- Bars will be generated by JS -->
                    </div>

                    <button type="button" class="record-btn" id="recordBtn" onclick="toggleRecording()">
                        <div class="record-icon"></div>
                    </button>

                    <div class="record-status">
                        <div class="record-time" id="recordTime">00:00:00</div>
                        <div class="record-hint" id="recordHint">Tap to start recording</div>
                        <div class="segment-indicator" id="segmentIndicator" style="display: none;">
                            <span class="segment-count" id="segmentCount">
                                <span class="segment-dot"></span>
                                <span id="segmentText">0 segments</span>
                            </span>
                        </div>
                    </div>

                    <div class="recording-controls" id="recordingControls" style="display: none;">
                        <button type="button" class="btn btn-secondary" onclick="discardRecording()">Discard All</button>
                        <button type="button" class="btn btn-primary btn-transcribe" id="transcribeBtn" onclick="transcribeRecording()">
                            Transcribe
                            <span class="pending-badge" id="pendingBadge" style="display: none;">1</span>
                        </button>
                    </div>

                    <div class="transcription-preview" id="transcriptionPreview">
                        <div class="transcription-header">
                            <span class="transcription-label">
                                Transcription
                                <span class="segment-count" id="transcribedCount" style="display: none;">
                                    <span class="segment-dot"></span>
                                    <span id="transcribedText">0 transcribed</span>
                                </span>
                            </span>
                            <div class="transcription-actions">
                                <button type="button" class="btn btn-small" onclick="editTranscription()">Edit</button>
                                <button type="button" class="btn btn-small" onclick="copyTranscription()">Copy</button>
                            </div>
                        </div>
                        <div class="transcription-text" id="transcriptionText"></div>
                    </div>
                </div>
            </div>
        </div>

        <button type="submit" class="btn btn-primary btn-large btn-submit" id="submitBtn">
            Submit Motif
        </button>
    </form>
</div>
{% endblock %}

{% block scripts %}
<script>
// Recording state machine
const RecordingState = {
    IDLE: 'idle',
    RECORDING: 'recording',
    PAUSED: 'paused'
};

// Voice recording state
let recordingState = RecordingState.IDLE;
let mediaRecorder = null;
let currentChunks = [];      // Chunks for current segment
let audioSegments = [];      // Array of {blob, transcribed: bool, transcript: string}
let audioStream = null;
let audioContext = null;
let analyser = null;
let recordingStartTime = null;
let pausedTime = 0;          // Accumulated time from previous segments
let timerInterval = null;
let voiceAvailable = false;
let currentMimeType = 'audio/webm';

// Accumulated transcript
let fullTranscript = '';

// Check voice availability on load
document.addEventListener('DOMContentLoaded', async function() {
    await checkVoiceAvailability();
    initVisualizer();
});

async function checkVoiceAvailability() {
    const voiceTabBtn = document.getElementById('voiceTabBtn');

    // Check browser support
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        voiceTabBtn.classList.add('disabled');
        voiceTabBtn.title = 'Voice recording not supported in this browser';
        return;
    }

    // Check if Whisper API is available
    try {
        const response = await fetch('/dropbox/api/transcribe/status');
        const data = await response.json();
        if (!data.available) {
            voiceTabBtn.classList.add('disabled');
            voiceTabBtn.title = 'Voice transcription not configured on server';
            return;
        }
    } catch (e) {
        console.error('Failed to check transcription status:', e);
    }

    voiceAvailable = true;
}

function initVisualizer() {
    const visualizer = document.getElementById('audioVisualizer');
    visualizer.innerHTML = '';
    // Create 32 bars for the visualizer
    for (let i = 0; i < 32; i++) {
        const bar = document.createElement('div');
        bar.className = 'visualizer-bar';
        bar.style.height = '4px';
        visualizer.appendChild(bar);
    }
}

function showTab(tab) {
    // Update tab buttons
    document.querySelectorAll('.tab-btn').forEach(btn => btn.classList.remove('active'));
    event.target.classList.add('active');

    // Update tab content
    document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
    document.getElementById('tab-' + tab).classList.add('active');

    // Clear other inputs when switching
    if (tab === 'text') {
        document.getElementById('file').value = '';
        document.getElementById('file-name').textContent = '';
        // Don't clear voice recording - user might want to switch back
    } else if (tab === 'file') {
        document.getElementById('transcript').value = '';
        // Don't clear voice recording
    } else if (tab === 'voice') {
        document.getElementById('file').value = '';
        document.getElementById('file-name').textContent = '';

        // Show appropriate UI based on availability
        if (!voiceAvailable) {
            document.getElementById('voiceUnavailable').style.display = 'block';
            document.getElementById('voiceRecorder').style.display = 'none';
        } else {
            document.getElementById('voiceUnavailable').style.display = 'none';
            document.getElementById('voiceRecorder').style.display = 'flex';
        }
    }
}

async function toggleRecording() {
    switch (recordingState) {
        case RecordingState.IDLE:
            await startRecording();
            break;
        case RecordingState.RECORDING:
            pauseRecording();
            break;
        case RecordingState.PAUSED:
            await resumeRecording();
            break;
    }
}

async function startRecording() {
    try {
        // Request microphone access
        audioStream = await navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true,
            }
        });

        // Set up audio context for visualization
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 64;
        const source = audioContext.createMediaStreamSource(audioStream);
        source.connect(analyser);

        // Determine best supported format
        currentMimeType = 'audio/webm';
        if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
            currentMimeType = 'audio/webm;codecs=opus';
        } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
            currentMimeType = 'audio/mp4';
        } else if (MediaRecorder.isTypeSupported('audio/ogg')) {
            currentMimeType = 'audio/ogg';
        }

        // Create MediaRecorder
        mediaRecorder = new MediaRecorder(audioStream, { mimeType: currentMimeType });
        currentChunks = [];

        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                currentChunks.push(event.data);
            }
        };

        mediaRecorder.onstop = () => {
            // Save current segment
            if (currentChunks.length > 0) {
                const segmentBlob = new Blob(currentChunks, { type: currentMimeType });
                audioSegments.push({
                    blob: segmentBlob,
                    transcribed: false,
                    transcript: ''
                });
                currentChunks = [];
                updateSegmentUI();
            }
        };

        // Start recording with chunking
        mediaRecorder.start(10000);
        recordingState = RecordingState.RECORDING;
        recordingStartTime = Date.now();

        // Update UI
        updateRecordingUI();

        // Start timer
        timerInterval = setInterval(updateTimer, 100);

        // Start visualizer
        visualize();

    } catch (error) {
        console.error('Failed to start recording:', error);
        if (error.name === 'NotAllowedError') {
            showError('Microphone access denied. Please allow microphone permissions.');
        } else if (error.name === 'NotFoundError') {
            showError('No microphone found. Please connect a microphone.');
        } else {
            showError('Failed to start recording: ' + error.message);
        }
    }
}

function pauseRecording() {
    if (!mediaRecorder || recordingState !== RecordingState.RECORDING) return;

    // Stop the current recording segment
    mediaRecorder.stop();
    recordingState = RecordingState.PAUSED;

    // Save elapsed time
    pausedTime += Date.now() - recordingStartTime;

    // Stop timer but keep the time
    if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
    }

    // Update UI
    updateRecordingUI();

    // Show controls
    document.getElementById('recordingControls').style.display = 'flex';
}

async function resumeRecording() {
    if (recordingState !== RecordingState.PAUSED) return;

    try {
        // Check if we need to get a new stream
        if (!audioStream || audioStream.getTracks().every(t => t.readyState === 'ended')) {
            audioStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                }
            });

            // Reconnect audio context
            if (audioContext.state === 'closed') {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 64;
            }
            const source = audioContext.createMediaStreamSource(audioStream);
            source.connect(analyser);
        }

        // Create new MediaRecorder for this segment
        mediaRecorder = new MediaRecorder(audioStream, { mimeType: currentMimeType });
        currentChunks = [];

        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                currentChunks.push(event.data);
            }
        };

        mediaRecorder.onstop = () => {
            if (currentChunks.length > 0) {
                const segmentBlob = new Blob(currentChunks, { type: currentMimeType });
                audioSegments.push({
                    blob: segmentBlob,
                    transcribed: false,
                    transcript: ''
                });
                currentChunks = [];
                updateSegmentUI();
            }
        };

        // Start recording
        mediaRecorder.start(10000);
        recordingState = RecordingState.RECORDING;
        recordingStartTime = Date.now();

        // Update UI
        updateRecordingUI();

        // Start timer
        timerInterval = setInterval(updateTimer, 100);

        // Start visualizer
        visualize();

    } catch (error) {
        console.error('Failed to resume recording:', error);
        showError('Failed to resume recording: ' + error.message);
    }
}

function updateRecordingUI() {
    const btn = document.getElementById('recordBtn');
    const visualizer = document.getElementById('audioVisualizer');
    const hint = document.getElementById('recordHint');
    const controls = document.getElementById('recordingControls');

    btn.classList.remove('recording', 'paused');
    visualizer.classList.remove('recording', 'paused');
    hint.classList.remove('recording', 'paused');

    switch (recordingState) {
        case RecordingState.IDLE:
            hint.textContent = 'Tap to start recording';
            controls.style.display = 'none';
            break;
        case RecordingState.RECORDING:
            btn.classList.add('recording');
            visualizer.classList.add('recording');
            hint.classList.add('recording');
            hint.textContent = 'Tap to pause';
            controls.style.display = 'none';
            break;
        case RecordingState.PAUSED:
            btn.classList.add('paused');
            visualizer.classList.add('paused');
            hint.classList.add('paused');
            hint.textContent = 'Tap to continue recording';
            controls.style.display = 'flex';
            break;
    }

    // Reset visualizer bars when not recording
    if (recordingState !== RecordingState.RECORDING) {
        const bars = document.querySelectorAll('.visualizer-bar');
        bars.forEach(bar => bar.style.height = '4px');
    }
}

function updateSegmentUI() {
    const indicator = document.getElementById('segmentIndicator');
    const segmentText = document.getElementById('segmentText');
    const pendingBadge = document.getElementById('pendingBadge');
    const transcribedCount = document.getElementById('transcribedCount');
    const transcribedText = document.getElementById('transcribedText');

    const totalSegments = audioSegments.length;
    const pendingSegments = audioSegments.filter(s => !s.transcribed).length;
    const transcribedSegments = totalSegments - pendingSegments;

    if (totalSegments > 0) {
        indicator.style.display = 'flex';
        segmentText.textContent = `${totalSegments} segment${totalSegments !== 1 ? 's' : ''}`;

        // Update pending badge
        if (pendingSegments > 0) {
            pendingBadge.style.display = 'flex';
            pendingBadge.textContent = pendingSegments;
        } else {
            pendingBadge.style.display = 'none';
        }

        // Update transcribed count
        if (transcribedSegments > 0) {
            transcribedCount.style.display = 'inline-flex';
            transcribedText.textContent = `${transcribedSegments} transcribed`;
        } else {
            transcribedCount.style.display = 'none';
        }
    } else {
        indicator.style.display = 'none';
        pendingBadge.style.display = 'none';
        transcribedCount.style.display = 'none';
    }
}

function updateTimer() {
    const elapsed = pausedTime + (recordingStartTime ? Date.now() - recordingStartTime : 0);
    const hours = Math.floor(elapsed / 3600000);
    const minutes = Math.floor((elapsed % 3600000) / 60000);
    const seconds = Math.floor((elapsed % 60000) / 1000);

    document.getElementById('recordTime').textContent =
        String(hours).padStart(2, '0') + ':' +
        String(minutes).padStart(2, '0') + ':' +
        String(seconds).padStart(2, '0');
}

function visualize() {
    if (!analyser || recordingState !== RecordingState.RECORDING) return;

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    analyser.getByteFrequencyData(dataArray);

    const bars = document.querySelectorAll('.visualizer-bar');
    const barCount = bars.length;

    for (let i = 0; i < barCount; i++) {
        const index = Math.floor(i * bufferLength / barCount);
        const value = dataArray[index];
        const height = Math.max(4, (value / 255) * 56);
        bars[i].style.height = height + 'px';
    }

    if (recordingState === RecordingState.RECORDING) {
        requestAnimationFrame(visualize);
    }
}

function discardRecording() {
    // Stop any ongoing recording
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
    }

    // Stop audio stream
    if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
        audioStream = null;
    }

    // Stop timer
    if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
    }

    // Close audio context
    if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
    }

    // Reset all state
    recordingState = RecordingState.IDLE;
    currentChunks = [];
    audioSegments = [];
    recordingStartTime = null;
    pausedTime = 0;
    fullTranscript = '';

    // Reset UI
    document.getElementById('recordTime').textContent = '00:00:00';
    document.getElementById('transcriptionPreview').classList.remove('visible');
    document.getElementById('transcriptionText').textContent = '';
    document.getElementById('transcript').value = '';

    updateRecordingUI();
    updateSegmentUI();

    showInfo('Recording discarded');
}

async function transcribeRecording() {
    // Find untranscribed segments
    const pendingSegments = audioSegments.filter(s => !s.transcribed);

    if (pendingSegments.length === 0) {
        showInfo('All segments already transcribed');
        return;
    }

    // Check total size of pending segments
    const totalSize = pendingSegments.reduce((sum, s) => sum + s.blob.size, 0);
    const maxSize = 25 * 1024 * 1024;

    if (totalSize > maxSize) {
        showError('Pending audio too large. Please transcribe in smaller chunks.');
        return;
    }

    // Show loading state
    const previewDiv = document.getElementById('transcriptionPreview');
    const textDiv = document.getElementById('transcriptionText');
    previewDiv.classList.add('visible');

    // Show existing transcript with loading indicator for new content
    const loadingHtml = '<div class="transcription-loading"><div class="loading-spinner"></div><span>Transcribing new segment...</span></div>';
    if (fullTranscript) {
        textDiv.innerHTML = fullTranscript + '<span class="segment-divider">New segment</span>' + loadingHtml;
    } else {
        textDiv.innerHTML = loadingHtml;
    }

    // Disable transcribe button
    const transcribeBtn = document.getElementById('transcribeBtn');
    transcribeBtn.disabled = true;
    transcribeBtn.childNodes[0].textContent = 'Transcribing...';

    try {
        // Combine all pending segments into one blob
        const pendingBlobs = pendingSegments.map(s => s.blob);
        const combinedBlob = new Blob(pendingBlobs, { type: currentMimeType });

        // Prepare form data
        const formData = new FormData();
        const ext = currentMimeType.includes('mp4') ? 'mp4' : currentMimeType.includes('ogg') ? 'ogg' : 'webm';
        formData.append('audio', combinedBlob, 'recording.' + ext);

        // Send to server
        const response = await fetch('/dropbox/api/transcribe', {
            method: 'POST',
            body: formData,
        });

        const data = await response.json();

        if (response.ok && data.success) {
            const newTranscript = data.transcript.trim();

            // Mark all pending segments as transcribed
            pendingSegments.forEach(s => {
                s.transcribed = true;
                s.transcript = newTranscript; // Store for reference
            });

            // Append to full transcript
            if (fullTranscript) {
                fullTranscript += '\n\n' + newTranscript;
            } else {
                fullTranscript = newTranscript;
            }

            // Update display
            textDiv.textContent = fullTranscript;

            // Update the hidden textarea for form submission
            document.getElementById('transcript').value = fullTranscript;

            updateSegmentUI();
            showSuccess('Transcription complete!');
        } else {
            // Restore previous transcript on error
            textDiv.textContent = fullTranscript || '';
            if (!fullTranscript) {
                previewDiv.classList.remove('visible');
            }
            showError(data.error || 'Transcription failed');
        }
    } catch (error) {
        console.error('Transcription error:', error);
        textDiv.textContent = fullTranscript || '';
        if (!fullTranscript) {
            previewDiv.classList.remove('visible');
        }
        showError('Network error during transcription');
    } finally {
        transcribeBtn.disabled = false;
        transcribeBtn.childNodes[0].textContent = 'Transcribe';
    }
}

function editTranscription() {
    // Switch to text tab with the transcript
    document.getElementById('transcript').value = fullTranscript;

    // Find and click the text tab button
    const textTabBtn = document.querySelector('.tab-btn');
    textTabBtn.click();

    // Focus the textarea
    setTimeout(() => {
        document.getElementById('transcript').focus();
    }, 100);
}

function copyTranscription() {
    if (!fullTranscript) return;

    navigator.clipboard.writeText(fullTranscript).then(() => {
        showSuccess('Copied to clipboard');
    }).catch(err => {
        showError('Failed to copy');
    });
}

// File input handling
document.getElementById('file').addEventListener('change', function(e) {
    const fileName = e.target.files[0]?.name || '';
    document.getElementById('file-name').textContent = fileName;

    if (fileName) {
        document.querySelector('.file-upload-content').innerHTML = `
            <svg class="upload-icon success" viewBox="0 0 24 24" width="48" height="48">
                <path fill="currentColor" d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41L9 16.17z"/>
            </svg>
            <p class="upload-text">${fileName}</p>
            <p class="upload-hint">Tap to change</p>
        `;
    }
});

// Form submission validation
document.getElementById('uploadForm').addEventListener('submit', function(e) {
    const text = document.getElementById('transcript').value.trim();
    const file = document.getElementById('file').files[0];
    const activeTab = document.querySelector('.tab-content.active').id;

    // If on voice tab with transcript, use the full transcript
    if (activeTab === 'tab-voice' && fullTranscript) {
        document.getElementById('transcript').value = fullTranscript;
        return; // Allow submission
    }

    if (!text && !file) {
        e.preventDefault();
        showWarning('Please enter text, select a file, or record a voice note.');
    }
});

// Warn before leaving with unsaved recording
window.addEventListener('beforeunload', function(e) {
    if (audioSegments.length > 0 || recordingState !== RecordingState.IDLE) {
        e.preventDefault();
        e.returnValue = 'You have an unsaved recording. Are you sure you want to leave?';
        return e.returnValue;
    }
});
</script>
{% endblock %}
